{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpandu/Object-detection/blob/master/training_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q_MQUJCX4xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq protobuf-compiler python-pil python-lxml\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive\n",
        "\n",
        "!pip install -q pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w9jwHjLYHU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRgYyCMuSKRJ",
        "colab_type": "code",
        "outputId": "eafbf8df-9394-406c-974d-2a8039133fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_P8qMS2IziUS",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/models/research')\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/models/research/slim/')\n",
        "sys.path.append('/content/models/research/object_detection/')\n",
        "sys.path.append('/content/models/research/')\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/:/content/models/research/object_detection/'\n",
        "\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!python object_detection/builders/model_builder_test.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kHGfdQl_76U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/datalab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvPtiOyr2JJ-",
        "colab_type": "code",
        "outputId": "cb687828-4180-466b-e830-b4461d993513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "%cd ~/datalab\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "MODEL = 'ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  opener = urllib.request.URLopener()\n",
        "  opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/datalab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgdEGfXv_9f0",
        "colab_type": "code",
        "outputId": "655e86d1-a1ab-4873-baf4-45f821d0d911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd ~/datalab/pretrained_model/saved_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/datalab/pretrained_model/saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYu7ASNibgat",
        "colab_type": "code",
        "outputId": "539a85dc-eb71-441d-ca24-0004ffaa0fc4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 10712
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Binary to run train and evaluation on object detection model.\"\"\"\n",
        "\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from absl import flags\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection import model_hparams\n",
        "from object_detection import model_lib\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "def del_all_flags(FLAGS):\n",
        "    flags_dict = FLAGS._flags()    \n",
        "    keys_list = [keys for keys in flags_dict]    \n",
        "    for keys in keys_list:\n",
        "        FLAGS.__delattr__(keys)\n",
        "\n",
        "del_all_flags(tf.flags.FLAGS)\n",
        "\n",
        "\n",
        "flags.DEFINE_string(\n",
        "    'model_dir', '/root/datalab/trained', 'Path to output model directory '\n",
        "    'where event and checkpoint files will be written.')\n",
        "flags.DEFINE_string('pipeline_config_path', 'ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config', 'Path to pipeline config '\n",
        "                    'file.')\n",
        "flags.DEFINE_integer('num_train_steps', 3000, 'Number of train steps.')\n",
        "flags.DEFINE_boolean('eval_training_data', False,\n",
        "                     'If training data should be evaluated for this job. Note '\n",
        "                     'that one call only use this in eval-only mode, and '\n",
        "                     '`checkpoint_dir` must be supplied.')\n",
        "flags.DEFINE_integer('sample_1_of_n_eval_examples', 1, 'Will sample one of '\n",
        "                     'every n eval input examples, where n is provided.')\n",
        "flags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '\n",
        "                     'one of every n train input examples for evaluation, '\n",
        "                     'where n is provided. This is only used if '\n",
        "                     '`eval_training_data` is True.')\n",
        "flags.DEFINE_string(\n",
        "    'hparams_overrides', None, 'Hyperparameter overrides, '\n",
        "    'represented as a string containing comma-separated '\n",
        "    'hparam_name=value pairs.')\n",
        "flags.DEFINE_string(\n",
        "    'checkpoint_dir', None, 'Path to directory holding a checkpoint.  If '\n",
        "    '`checkpoint_dir` is provided, this binary operates in eval-only mode, '\n",
        "    'writing resulting metrics to `model_dir`.')\n",
        "flags.DEFINE_boolean(\n",
        "    'run_once', True, 'If running in eval-only mode, whether to run just '\n",
        "    'one round of eval vs running continuously (default).'\n",
        ")\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def main(unused_argv):\n",
        "  flags.mark_flag_as_required('model_dir')\n",
        "  flags.mark_flag_as_required('pipeline_config_path')\n",
        "  config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir, log_step_count_steps= 300, save_checkpoints_steps = 500)\n",
        "\n",
        "  train_and_eval_dict = model_lib.create_estimator_and_inputs(\n",
        "      run_config=config,\n",
        "      hparams=model_hparams.create_hparams(FLAGS.hparams_overrides),\n",
        "      pipeline_config_path=FLAGS.pipeline_config_path,\n",
        "      train_steps=FLAGS.num_train_steps,\n",
        "      sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,\n",
        "      sample_1_of_n_eval_on_train_examples=(\n",
        "          FLAGS.sample_1_of_n_eval_on_train_examples))\n",
        "  estimator = train_and_eval_dict['estimator']\n",
        "  train_input_fn = train_and_eval_dict['train_input_fn']\n",
        "  eval_input_fns = train_and_eval_dict['eval_input_fns']\n",
        "  eval_on_train_input_fn = train_and_eval_dict['eval_on_train_input_fn']\n",
        "  predict_input_fn = train_and_eval_dict['predict_input_fn']\n",
        "  train_steps = train_and_eval_dict['train_steps']\n",
        "\n",
        "  if FLAGS.checkpoint_dir:\n",
        "    if FLAGS.eval_training_data:\n",
        "      name = 'training_data'\n",
        "      input_fn = eval_on_train_input_fn\n",
        "    else:\n",
        "      name = 'validation_data'\n",
        "      # The first eval input will be evaluated.\n",
        "      input_fn = eval_input_fns[0]\n",
        "    if FLAGS.run_once:\n",
        "      estimator.evaluate(input_fn,\n",
        "                         num_eval_steps=None,\n",
        "                         checkpoint_path=tf.train.latest_checkpoint(\n",
        "                             FLAGS.checkpoint_dir))\n",
        "    else:\n",
        "      model_lib.continuous_eval(estimator, FLAGS.checkpoint_dir, input_fn,\n",
        "                                train_steps, name)\n",
        "  else:\n",
        "    train_spec, eval_specs = model_lib.create_train_and_eval_specs(\n",
        "        train_input_fn,\n",
        "        eval_input_fns,\n",
        "        eval_on_train_input_fn,\n",
        "        predict_input_fn,\n",
        "        train_steps,\n",
        "        eval_on_train_data=False)\n",
        "\n",
        "    # Currently only a single Eval Spec is allowed.\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-98bbbe20-e2e6-40f9-b527-3f0ba02f1f17\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-98bbbe20-e2e6-40f9-b527-3f0ba02f1f17\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving person_label_map.pbtxt to person_label_map.pbtxt\n",
            "Saving ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config to ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config\n",
            "Saving test.record to test.record\n",
            "Saving train.record to train.record\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 3000\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/root/datalab/trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 300, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5bd20376a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f5bd1b4d2f0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 500 or save_checkpoints_secs None.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/absl/flags/_validators.py:359: UserWarning: Flag --model_dir has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
            "  'command line!' % flag_name)\n",
            "/usr/local/lib/python3.6/dist-packages/absl/flags/_validators.py:359: UserWarning: Flag --pipeline_config_path has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
            "  'command line!' % flag_name)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:472: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:320: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:1240: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the `axis` argument instead\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:152: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Variable [MobilenetV1/Conv2d_0/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_0/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_0/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_0/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_0/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_10_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_10_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_10_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_10_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_10_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_10_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_11_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_11_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_11_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_11_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_11_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_11_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_12_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_12_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_12_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_12_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_12_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_12_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_13_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_13_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_13_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_1_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_1_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_1_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_1_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_1_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_1_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_2_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_2_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_2_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_2_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_2_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_2_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_3_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_3_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_3_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_3_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_3_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_3_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_4_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_4_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_4_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_4_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_4_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_4_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_5_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_5_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_5_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_5_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_5_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_5_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_6_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_6_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_6_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_6_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_6_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_6_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_7_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_7_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_7_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_7_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_7_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_7_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_8_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_8_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_8_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_8_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_8_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_8_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_9_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_9_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_9_depthwise/depthwise_weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_9_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_9_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/Conv2d_9_pointwise/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/bottom_up_Conv2d_14/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/bottom_up_Conv2d_14/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/bottom_up_Conv2d_14/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/bottom_up_Conv2d_14/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/bottom_up_Conv2d_14/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/bottom_up_Conv2d_15/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/bottom_up_Conv2d_15/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/bottom_up_Conv2d_15/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/bottom_up_Conv2d_15/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/bottom_up_Conv2d_15/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/projection_1/biases] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/projection_1/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/projection_2/biases] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/projection_2/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/projection_3/biases] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/projection_3/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/smoothing_1/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/smoothing_1/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/smoothing_1/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/smoothing_1/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/smoothing_1/weights] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/smoothing_2/BatchNorm/beta] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/smoothing_2/BatchNorm/gamma] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/smoothing_2/BatchNorm/moving_mean] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/smoothing_2/BatchNorm/moving_variance] is not available in checkpoint\n",
            "WARNING:root:Variable [MobilenetV1/fpn/smoothing_2/weights] is not available in checkpoint\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.9688684, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.9688684, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.455483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.455483\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.5130369, step = 300 (658.648 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.5130369, step = 300 (658.648 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 500 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 500 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:785: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:785: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, use\n",
            "    tf.py_function, which takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, use\n",
            "    tf.py_function, which takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T05:52:17Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T05:52:17Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.00s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.00s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.58s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.109\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.224\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-18-05:52:24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-18-05:52:24\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 500: DetectionBoxes_Precision/mAP = 0.020506743, DetectionBoxes_Precision/mAP (large) = 0.021439655, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.10946549, DetectionBoxes_Precision/mAP@.75IOU = 0.00030947887, DetectionBoxes_Recall/AR@1 = 0.017045455, DetectionBoxes_Recall/AR@10 = 0.09318182, DetectionBoxes_Recall/AR@100 = 0.21363637, DetectionBoxes_Recall/AR@100 (large) = 0.22380953, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.8566103, Loss/localization_loss = 0.62362564, Loss/regularization_loss = 0.084994085, Loss/total_loss = 1.5652299, global_step = 500, learning_rate = 0.01999975, loss = 1.5652299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 500: DetectionBoxes_Precision/mAP = 0.020506743, DetectionBoxes_Precision/mAP (large) = 0.021439655, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.10946549, DetectionBoxes_Precision/mAP@.75IOU = 0.00030947887, DetectionBoxes_Recall/AR@1 = 0.017045455, DetectionBoxes_Recall/AR@10 = 0.09318182, DetectionBoxes_Recall/AR@100 = 0.21363637, DetectionBoxes_Recall/AR@100 (large) = 0.22380953, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.8566103, Loss/localization_loss = 0.62362564, Loss/regularization_loss = 0.084994085, Loss/total_loss = 1.5652299, global_step = 500, learning_rate = 0.01999975, loss = 1.5652299\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: /root/datalab/trained/model.ckpt-500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: /root/datalab/trained/model.ckpt-500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.450415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.450415\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.34910026, step = 600 (666.052 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.34910026, step = 600 (666.052 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.461904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.461904\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.29754588, step = 900 (649.485 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.29754588, step = 900 (649.485 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1000 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1000 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T06:10:35Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T06:10:35Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-1000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.01s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.01s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.50s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-18-06:10:41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-18-06:10:41\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 1000: DetectionBoxes_Precision/mAP = 0.017565405, DetectionBoxes_Precision/mAP (large) = 0.01840368, DetectionBoxes_Precision/mAP (medium) = 0.00024516738, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.09024331, DetectionBoxes_Precision/mAP@.75IOU = 0.0003406504, DetectionBoxes_Recall/AR@1 = 0.0045454544, DetectionBoxes_Recall/AR@10 = 0.045454547, DetectionBoxes_Recall/AR@100 = 0.30795455, DetectionBoxes_Recall/AR@100 (large) = 0.32142857, DetectionBoxes_Recall/AR@100 (medium) = 0.025, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 1.0311341, Loss/localization_loss = 0.59713227, Loss/regularization_loss = 0.085079275, Loss/total_loss = 1.7133458, global_step = 1000, learning_rate = 0.0266665, loss = 1.7133458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 1000: DetectionBoxes_Precision/mAP = 0.017565405, DetectionBoxes_Precision/mAP (large) = 0.01840368, DetectionBoxes_Precision/mAP (medium) = 0.00024516738, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.09024331, DetectionBoxes_Precision/mAP@.75IOU = 0.0003406504, DetectionBoxes_Recall/AR@1 = 0.0045454544, DetectionBoxes_Recall/AR@10 = 0.045454547, DetectionBoxes_Recall/AR@100 = 0.30795455, DetectionBoxes_Recall/AR@100 (large) = 0.32142857, DetectionBoxes_Recall/AR@100 (medium) = 0.025, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 1.0311341, Loss/localization_loss = 0.59713227, Loss/regularization_loss = 0.085079275, Loss/total_loss = 1.7133458, global_step = 1000, learning_rate = 0.0266665, loss = 1.7133458\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /root/datalab/trained/model.ckpt-1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /root/datalab/trained/model.ckpt-1000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.45276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.45276\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.22935861, step = 1200 (662.606 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.22935861, step = 1200 (662.606 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1500 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1500 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T06:28:51Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T06:28:51Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-1500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-1500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.00s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.00s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.232\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-18-06:28:57\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-18-06:28:57\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 1500: DetectionBoxes_Precision/mAP = 0.014474741, DetectionBoxes_Precision/mAP (large) = 0.01590555, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.05836229, DetectionBoxes_Precision/mAP@.75IOU = 0.004390883, DetectionBoxes_Recall/AR@1 = 0.010227272, DetectionBoxes_Recall/AR@10 = 0.07840909, DetectionBoxes_Recall/AR@100 = 0.2215909, DetectionBoxes_Recall/AR@100 (large) = 0.23214285, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 1.4280052, Loss/localization_loss = 0.9431576, Loss/regularization_loss = 0.084942125, Loss/total_loss = 2.4561043, global_step = 1500, learning_rate = 0.03333325, loss = 2.4561043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 1500: DetectionBoxes_Precision/mAP = 0.014474741, DetectionBoxes_Precision/mAP (large) = 0.01590555, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.05836229, DetectionBoxes_Precision/mAP@.75IOU = 0.004390883, DetectionBoxes_Recall/AR@1 = 0.010227272, DetectionBoxes_Recall/AR@10 = 0.07840909, DetectionBoxes_Recall/AR@100 = 0.2215909, DetectionBoxes_Recall/AR@100 (large) = 0.23214285, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 1.4280052, Loss/localization_loss = 0.9431576, Loss/regularization_loss = 0.084942125, Loss/total_loss = 2.4561043, global_step = 1500, learning_rate = 0.03333325, loss = 2.4561043\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1500: /root/datalab/trained/model.ckpt-1500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1500: /root/datalab/trained/model.ckpt-1500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.452292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.452292\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.24114689, step = 1500 (663.284 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.24114689, step = 1500 (663.284 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.460946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.460946\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.19402084, step = 1800 (650.838 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.19402084, step = 1800 (650.838 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2000 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2000 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T06:47:10Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T06:47:10Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-2000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.00s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.00s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.47s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.632\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-18-06:47:16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-18-06:47:16\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 2000: DetectionBoxes_Precision/mAP = 0.23970525, DetectionBoxes_Precision/mAP (large) = 0.25218078, DetectionBoxes_Precision/mAP (medium) = 7.661481e-05, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.632067, DetectionBoxes_Precision/mAP@.75IOU = 0.13026516, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.4465909, DetectionBoxes_Recall/AR@100 = 0.53636366, DetectionBoxes_Recall/AR@100 (large) = 0.5607143, DetectionBoxes_Recall/AR@100 (medium) = 0.025, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.6259566, Loss/localization_loss = 0.30184072, Loss/regularization_loss = 0.08459783, Loss/total_loss = 1.0123951, global_step = 2000, learning_rate = 0.04, loss = 1.0123951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 2000: DetectionBoxes_Precision/mAP = 0.23970525, DetectionBoxes_Precision/mAP (large) = 0.25218078, DetectionBoxes_Precision/mAP (medium) = 7.661481e-05, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.632067, DetectionBoxes_Precision/mAP@.75IOU = 0.13026516, DetectionBoxes_Recall/AR@1 = 0.1375, DetectionBoxes_Recall/AR@10 = 0.4465909, DetectionBoxes_Recall/AR@100 = 0.53636366, DetectionBoxes_Recall/AR@100 (large) = 0.5607143, DetectionBoxes_Recall/AR@100 (medium) = 0.025, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.6259566, Loss/localization_loss = 0.30184072, Loss/regularization_loss = 0.08459783, Loss/total_loss = 1.0123951, global_step = 2000, learning_rate = 0.04, loss = 1.0123951\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /root/datalab/trained/model.ckpt-2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /root/datalab/trained/model.ckpt-2000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.45131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.45131\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.21429461, step = 2100 (664.730 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.21429461, step = 2100 (664.730 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.460494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.460494\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.16718665, step = 2400 (651.472 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.16718665, step = 2400 (651.472 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2500 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2500 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T07:05:28Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T07:05:28Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-2500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.01s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.01s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.49s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.701\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.456\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-18-07:05:34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-18-07:05:34\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 2500: DetectionBoxes_Precision/mAP = 0.29954442, DetectionBoxes_Precision/mAP (large) = 0.31654772, DetectionBoxes_Precision/mAP (medium) = 0.00062127656, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.70137215, DetectionBoxes_Precision/mAP@.75IOU = 0.1759269, DetectionBoxes_Recall/AR@1 = 0.17840908, DetectionBoxes_Recall/AR@10 = 0.45568183, DetectionBoxes_Recall/AR@100 = 0.5318182, DetectionBoxes_Recall/AR@100 (large) = 0.552381, DetectionBoxes_Recall/AR@100 (medium) = 0.1, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.6618343, Loss/localization_loss = 0.2603287, Loss/regularization_loss = 0.08408237, Loss/total_loss = 1.0062453, global_step = 2500, learning_rate = 0.039953373, loss = 1.0062453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 2500: DetectionBoxes_Precision/mAP = 0.29954442, DetectionBoxes_Precision/mAP (large) = 0.31654772, DetectionBoxes_Precision/mAP (medium) = 0.00062127656, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.70137215, DetectionBoxes_Precision/mAP@.75IOU = 0.1759269, DetectionBoxes_Recall/AR@1 = 0.17840908, DetectionBoxes_Recall/AR@10 = 0.45568183, DetectionBoxes_Recall/AR@100 = 0.5318182, DetectionBoxes_Recall/AR@100 (large) = 0.552381, DetectionBoxes_Recall/AR@100 (medium) = 0.1, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.6618343, Loss/localization_loss = 0.2603287, Loss/regularization_loss = 0.08408237, Loss/total_loss = 1.0062453, global_step = 2500, learning_rate = 0.039953373, loss = 1.0062453\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: /root/datalab/trained/model.ckpt-2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: /root/datalab/trained/model.ckpt-2500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.452049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.452049\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2046526, step = 2700 (663.650 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2046526, step = 2700 (663.650 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 3000 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 3000 into /root/datalab/trained/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T07:23:46Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-18T07:23:46Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-3000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loading and preparing annotation results...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.01s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:DONE (t=0.01s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.49s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.696\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.135\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-18-07:23:52\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-18-07:23:52\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 3000: DetectionBoxes_Precision/mAP = 0.2612295, DetectionBoxes_Precision/mAP (large) = 0.28116837, DetectionBoxes_Precision/mAP (medium) = 3.5360677e-05, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6956144, DetectionBoxes_Precision/mAP@.75IOU = 0.13524403, DetectionBoxes_Recall/AR@1 = 0.13522728, DetectionBoxes_Recall/AR@10 = 0.44431818, DetectionBoxes_Recall/AR@100 = 0.53409094, DetectionBoxes_Recall/AR@100 (large) = 0.55833334, DetectionBoxes_Recall/AR@100 (medium) = 0.025, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.6097689, Loss/localization_loss = 0.2633666, Loss/regularization_loss = 0.08346573, Loss/total_loss = 0.95660114, global_step = 3000, learning_rate = 0.03981372, loss = 0.95660114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 3000: DetectionBoxes_Precision/mAP = 0.2612295, DetectionBoxes_Precision/mAP (large) = 0.28116837, DetectionBoxes_Precision/mAP (medium) = 3.5360677e-05, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6956144, DetectionBoxes_Precision/mAP@.75IOU = 0.13524403, DetectionBoxes_Recall/AR@1 = 0.13522728, DetectionBoxes_Recall/AR@10 = 0.44431818, DetectionBoxes_Recall/AR@100 = 0.53409094, DetectionBoxes_Recall/AR@100 (large) = 0.55833334, DetectionBoxes_Recall/AR@100 (medium) = 0.025, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.6097689, Loss/localization_loss = 0.2633666, Loss/regularization_loss = 0.08346573, Loss/total_loss = 0.95660114, global_step = 3000, learning_rate = 0.03981372, loss = 0.95660114\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: /root/datalab/trained/model.ckpt-3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: /root/datalab/trained/model.ckpt-3000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Performing the final export in the end of training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Performing the final export in the end of training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/datalab/trained/model.ckpt-3000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /root/datalab/trained/export/Servo/temp-b'1558164232'/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /root/datalab/trained/export/Servo/temp-b'1558164232'/saved_model.pb\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.17799361.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.17799361.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtobkZ1-ci3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def getFileFromGDrive():\n",
        "  # Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  # Load training files from drive, eed to provide <File_ID> thats has train and test files\n",
        "  file_list = drive.ListFile({'q': \"'1o_7AiI5h-R6ndusa6AlReULNRTl_FWML' in parents and trashed=false\"}).GetList()   \n",
        "  \n",
        "  file_name11 = file_list[0]['title']\n",
        "  print('training/test data: %s' % file_name11)\n",
        "  \n",
        "  for filename in file_list:\n",
        "    if not os.path.exists(filename['title']):\n",
        "      test_downloaded = drive.CreateFile({'id': filename['id']})\n",
        "      test_downloaded.GetContentFile(filename['title']) \n",
        "      print('Successfully loaded the files.')\n",
        "  return drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNX64QZ7eTz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getFileFromGDrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yEYeud9azC0b",
        "colab": {}
      },
      "source": [
        "%cd ~/datalab\n",
        "\n",
        "lst = os.listdir('/root/datalab/trained')\n",
        "lf = filter(lambda k: 'model.ckpt-' in k, lst)\n",
        "last_model = sorted(lf)[-1].replace('.meta', '')\n",
        "\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config \\\n",
        "    --output_directory=fine_tuned_model \\\n",
        "    --trained_checkpoint_prefix=trained/$last_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkyLOWi-f1PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "files.download('/root/datalab/fine_tuned_model/frozen_inference_graph.pb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL6Zkfq_6jS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files\n",
        "\n",
        "def getFileFromGDrive():\n",
        "  # Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  return drive\n",
        "\n",
        "drive = getFileFromGDrive()\n",
        "uploaded = drive.CreateFile({'title':'frozen_inference_graph.pb'})\n",
        "uploaded.SetContentFile('/root/datalab/fine_tuned_model/frozen_inference_graph.pb')\n",
        "uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH4LJ6LMdHUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU1tLO2MzPZB",
        "colab_type": "code",
        "outputId": "71bb14ac-ed3c-44b6-e448-a6c03c542e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "%cd /root\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "from object_detection.utils import ops as utils_ops\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile('/root/datalab/fine_tuned_model/frozen_inference_graph.pb', 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "category_index = label_map_util.create_category_index_from_labelmap('/root/person_label_map.pbtxt', use_display_name=True)\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "  \n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (6, 5)\n",
        "\n",
        "for image_path in os.listdir(\"/root/data2/\"):\n",
        "  image = Image.open('/root/data2/'+image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  max_open_warning, RuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg2JCQJHeoOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /root/ssd_inception_v2_coco.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDA671NKdjd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('/root/datalab/trained')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}